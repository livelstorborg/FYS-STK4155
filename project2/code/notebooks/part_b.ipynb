{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebf0cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/Users/livestorborg/Desktop/FYS-STK4155/project2/code')\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.neural_network import NeuralNetwork\n",
    "from src.activations import Sigmoid, Linear\n",
    "from src.losses import MSE\n",
    "from src.optimizers import GD, RMSprop, Adam\n",
    "from src.training import train\n",
    "from src.metrics import mse\n",
    "from src.utils import runge, polynomial_features, scale_data, OLS_parameters, inverse_scale_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52920845",
   "metadata": {},
   "source": [
    "# Setup for OLS Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6128ad17",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "N = 300\n",
    "x = np.linspace(-1, 1, N)\n",
    "y_true = runge(x)\n",
    "y_noise = y_true + np.random.normal(0, 0.01, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4c5910",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_poly = polynomial_features(x, p=14, intercept=False)\n",
    "\n",
    "X_train_poly, X_test_poly, y_train, y_test = train_test_split(\n",
    "    X_poly, y_noise, test_size=0.2, random_state=SEED\n",
    ")\n",
    "\n",
    "theta_ols = OLS_parameters(X_train_poly, y_train)\n",
    "y_pred_ols = X_test_poly @ theta_ols\n",
    "ols_mse = mse(y_test.reshape(-1, 1), y_pred_ols.reshape(-1, 1))\n",
    "\n",
    "print(f\"OLS Test MSE: {ols_mse:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098f3a8f",
   "metadata": {},
   "source": [
    "# Setup for FFNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1af3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw, X_test_raw, y_train_nn, y_test_nn = train_test_split(\n",
    "    x.reshape(-1, 1), y_noise.reshape(-1, 1), \n",
    "    test_size=0.2, random_state=SEED\n",
    ")\n",
    "\n",
    "# Scale\n",
    "X_train_s, y_train_s, X_mean, X_std, y_mean = scale_data(X_train_raw, y_train_nn)\n",
    "X_test_s, y_test_s, _, _, _ = scale_data(X_test_raw, y_test_nn, X_mean, X_std, y_mean)\n",
    "\n",
    "y_test_real = inverse_scale_y(y_test_s, y_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5686bb",
   "metadata": {},
   "source": [
    "# Learning rates to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd781a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eta_gd = np.logspace(-3, 1, 20)     \n",
    "eta_rms = np.logspace(-3, -1, 20)    \n",
    "eta_adam = np.logspace(-3, -1, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fcbddf",
   "metadata": {},
   "source": [
    "# Parameters for FFNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a953ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_input_size = 1\n",
    "loss = MSE()\n",
    "\n",
    "# Experiment 1: one hidden layer and 50 hidden nodes\n",
    "layer_output_sizes_1 = [50, 1]\n",
    "activations_1 = [Sigmoid(), Linear()]\n",
    "\n",
    "# Experiment 2: two hidden layers and 100 hidden nodes each\n",
    "layer_output_sizes_2 = [100, 100, 1]\n",
    "activations_2 = [Sigmoid(), Sigmoid(), Linear()]\n",
    "\n",
    "\n",
    "num_iter = 500     # GD full batch\n",
    "epochs = 500       # RMSprop and Adam (mini-batch)\n",
    "batch_size = 32    # RMSprop and Adam (mini-batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316bb99c",
   "metadata": {},
   "source": [
    "# Full batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe788b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_gd_eta_1 = None\n",
    "best_gd_mse_1 = float('inf')\n",
    "\n",
    "best_gd_eta_2 = None\n",
    "best_gd_mse_2 = float('inf')\n",
    "\n",
    "for eta in eta_gd:\n",
    "\n",
    "    # Experiment 1: one hidden layer and 50 hidden nodes\n",
    "    nn_gd_1 = NeuralNetwork(network_input_size=network_input_size, layer_output_sizes=layer_output_sizes_1, activations=activations_1, loss=loss, seed=SEED)\n",
    "    train(nn_gd_1, X_train_s, y_train_s, X_test_s, y_test_s, GD(eta), \n",
    "          epochs=500, batch_size=len(X_train_s), verbose=False, seed=SEED) \n",
    "    y_pred_gd_s = nn_gd_1.predict(X_test_s)\n",
    "    y_pred_gd = inverse_scale_y(y_pred_gd_s, y_mean)\n",
    "    gd_mse = mse(y_test_real, y_pred_gd)\n",
    "\n",
    "    print(f\"  eta={eta:.4f}  MSE={gd_mse:.6f}\")\n",
    "\n",
    "    if gd_mse < best_gd_mse_1:  \n",
    "        best_gd_mse_1 = gd_mse\n",
    "        best_gd_eta_1 = eta\n",
    "\n",
    "    # Experiment 2: two hidden layers and 100 hidden nodes each\n",
    "    nn_gd_2 = NeuralNetwork(network_input_size=network_input_size, layer_output_sizes=layer_output_sizes_2, activations=activations_2, loss=loss, seed=SEED)\n",
    "    train(nn_gd_2, X_train_s, y_train_s, X_test_s, y_test_s, GD(eta), \n",
    "          epochs=500, batch_size=len(X_train_s), verbose=False, seed=SEED) \n",
    "    y_pred_gd_s = nn_gd_2.predict(X_test_s)\n",
    "    y_pred_gd = inverse_scale_y(y_pred_gd_s, y_mean)\n",
    "    gd_mse = mse(y_test_real, y_pred_gd)\n",
    "\n",
    "    print(f\"  eta={eta:.4f}  MSE={gd_mse:.6f}\")\n",
    "\n",
    "    if gd_mse < best_gd_mse_2:  \n",
    "        best_gd_mse_2 = gd_mse\n",
    "        best_gd_eta_2 = eta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a501179",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent with RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c91bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rms_eta_1 = None\n",
    "best_rms_mse_1 = float('inf')\n",
    "\n",
    "best_rms_eta_2 = None\n",
    "best_rms_mse_2 = float('inf')\n",
    "\n",
    "for eta in eta_rms:\n",
    "\n",
    "    # Experiment 1: one hidden layer and 50 hidden nodes\n",
    "    nn_rms_1 = NeuralNetwork(network_input_size=network_input_size, layer_output_sizes=layer_output_sizes_1, activations=activations_1, loss=loss, seed=SEED)\n",
    "    train(nn_rms_1, X_train_s, y_train_s, X_test_s, y_test_s, RMSprop(eta), \n",
    "          epochs=500, batch_size=batch_size, verbose=False, seed=SEED) \n",
    "    y_pred_rms_s = nn_rms_1.predict(X_test_s)\n",
    "    y_pred_rms = inverse_scale_y(y_pred_rms_s, y_mean)\n",
    "    rms_mse = mse(y_test_real, y_pred_rms)\n",
    "\n",
    "    print(f\"  eta={eta:.4f}  MSE={rms_mse:.6f}\")\n",
    "\n",
    "    if rms_mse < best_rms_mse_1:  \n",
    "        best_rms_mse_1 = rms_mse\n",
    "        best_rms_eta_1 = eta\n",
    "\n",
    "    # Experiment 2: two hidden layers and 100 hidden nodes each\n",
    "    nn_rms_2 = NeuralNetwork(network_input_size=network_input_size, layer_output_sizes=layer_output_sizes_2, activations=activations_2, loss=loss, seed=SEED)\n",
    "    train(nn_rms_2, X_train_s, y_train_s, X_test_s, y_test_s, RMSprop(eta), \n",
    "          epochs=500, batch_size=batch_size, verbose=False, seed=SEED) \n",
    "    y_pred_rms_s = nn_rms_2.predict(X_test_s)\n",
    "    y_pred_rms = inverse_scale_y(y_pred_rms_s, y_mean)\n",
    "    rms_mse = mse(y_test_real, y_pred_rms)\n",
    "\n",
    "    print(f\"  eta={eta:.4f}  MSE={rms_mse:.6f}\")\n",
    "\n",
    "    if rms_mse < best_rms_mse_2:  \n",
    "        best_rms_mse_2 = rms_mse\n",
    "        best_rms_eta_2 = eta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c514cf",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent with Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42722fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_adam_eta_1 = None\n",
    "best_adam_mse_1 = float('inf')\n",
    "\n",
    "best_adam_eta_2 = None\n",
    "best_adam_mse_2 = float('inf')\n",
    "\n",
    "for eta in eta_adam:\n",
    "\n",
    "    # Experiment 1: one hidden layer and 50 hidden nodes\n",
    "    nn_adam_1 = NeuralNetwork(network_input_size=network_input_size, layer_output_sizes=layer_output_sizes_1, activations=activations_1, loss=loss, seed=SEED)\n",
    "    train(nn_adam_1, X_train_s, y_train_s, X_test_s, y_test_s, Adam(eta),\n",
    "          epochs=500, batch_size=batch_size, verbose=False, seed=SEED) \n",
    "    y_pred_adam_s = nn_adam_1.predict(X_test_s)\n",
    "    y_pred_adam = inverse_scale_y(y_pred_adam_s, y_mean)\n",
    "    adam_mse = mse(y_test_real, y_pred_adam)\n",
    "\n",
    "    print(f\"  eta={eta:.4f}  MSE={rms_mse:.6f}\")\n",
    "\n",
    "    if rms_mse < best_adam_mse_1:  \n",
    "        best_adam_mse_1 = rms_mse\n",
    "        best_adam_eta_1 = eta\n",
    "\n",
    "    # Experiment 2: two hidden layers and 100 hidden nodes each\n",
    "    nn_adam_2 = NeuralNetwork(network_input_size=network_input_size, layer_output_sizes=layer_output_sizes_2, activations=activations_2, loss=loss, seed=SEED)\n",
    "    train(nn_adam_2, X_train_s, y_train_s, X_test_s, y_test_s, Adam(eta), \n",
    "          epochs=500, batch_size=batch_size, verbose=False, seed=SEED) \n",
    "    y_pred_adam_s = nn_adam_2.predict(X_test_s)\n",
    "    y_pred_adam = inverse_scale_y(y_pred_adam_s, y_mean)\n",
    "    adam_mse = mse(y_test_real, y_pred_adam)\n",
    "\n",
    "    print(f\"  eta={eta:.4f}  MSE={adam_mse:.6f}\")\n",
    "\n",
    "    if adam_mse < best_adam_mse_2:  \n",
    "        best_adam_mse_2 = adam_mse\n",
    "        best_adam_eta_2 = eta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736c5ab9",
   "metadata": {},
   "source": [
    "# Results for one hidden layer and 50 hidden nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97dd97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ONE HIDDEN LAYER & 50 HIDDEN NODES\")\n",
    "print(\"=\"*50)\n",
    "print(f\"OLS (deg 14):      {ols_mse:.6f}\")\n",
    "print(f\"NN + GD:           {best_gd_mse_1:.6f}  (eta={best_gd_eta_1:.4f})\")\n",
    "print(f\"NN + RMSprop:      {best_rms_mse_1:.6f}  (eta={best_rms_eta_1:.4f})\")\n",
    "print(f\"NN + Adam:         {best_adam_mse_1:.6f}  (eta={best_adam_eta_1:.4f})\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c6e320",
   "metadata": {},
   "source": [
    "# Results for two hidden layers and 100 hidden nodes each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66884f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TWO HIDDEN LAYERS & 100 HIDDEN NODES EACH\")\n",
    "print(\"=\"*50)\n",
    "print(f\"OLS (deg 14):      {ols_mse:.6f}\")\n",
    "print(f\"NN + GD:           {best_gd_mse_2:.6f}  (eta={best_gd_eta_2:.4f})\")\n",
    "print(f\"NN + RMSprop:      {best_rms_mse_2:.6f}  (eta={best_rms_eta_2:.4f})\")\n",
    "print(f\"NN + Adam:         {best_adam_mse_2:.6f}  (eta={best_adam_eta_2:.4f})\")\n",
    "print(\"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Project 2",
   "language": "python",
   "name": "project2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
