{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bb7c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, '/Users/livestorborg/Desktop/FYS-STK4155/project2/code')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "from src.neural_network import NeuralNetwork\n",
    "from src.activations import Sigmoid, Linear\n",
    "from src.losses import MSE\n",
    "from src.optimizers import Adam, RMSprop\n",
    "from src.training import train\n",
    "from src.metrics import mse\n",
    "from src.utils import runge, polynomial_features, scale_data, inverse_scale_y\n",
    "from src.plotting import lambda_eta_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d29fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "N = 100\n",
    "x = np.linspace(-1, 1, N)\n",
    "y_true = runge(x)\n",
    "y_noise = y_true + np.random.normal(0, 0.1, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd721543",
   "metadata": {},
   "source": [
    "# Setup for Lasso Regression (using Scikit-learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27d5cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_poly = polynomial_features(x, p=9, intercept=False)\n",
    "\n",
    "X_train_poly, X_test_poly, y_train, y_test = train_test_split(\n",
    "    X_poly, y_noise, test_size=0.2, random_state=SEED\n",
    ")\n",
    "# Scale data\n",
    "X_train_s, y_train_s, X_mean, X_std, y_mean = scale_data(X_train_poly, y_train)\n",
    "X_test_s, y_test_s, _, _, _ = scale_data(\n",
    "    X_test_poly, y_test, X_mean, X_std, y_mean\n",
    ")\n",
    "\n",
    "lasso_model = Lasso(alpha=0.01, max_iter=10000, random_state=SEED)\n",
    "lasso_model.fit(X_train_s, y_train_s.ravel())\n",
    "y_pred_lasso = lasso_model.predict(X_test_s)\n",
    "lasso_mse = mse(y_test_s.reshape(-1, 1), y_pred_lasso.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c777d11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw, X_test_raw, y_train_nn, y_test_nn = train_test_split(\n",
    "    x.reshape(-1, 1), y_noise.reshape(-1, 1), \n",
    "    test_size=0.2, random_state=SEED\n",
    ")\n",
    "\n",
    "# Scale for NN\n",
    "X_train_s, y_train_s, X_mean, X_std, y_mean = scale_data(X_train_raw, y_train_nn)\n",
    "X_test_s, y_test_s, _, _, _ = scale_data(X_test_raw, y_test_nn, X_mean, X_std, y_mean)\n",
    "\n",
    "# Compute y_test_real once (used in all loops)\n",
    "y_test_real = inverse_scale_y(y_test_s, y_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac00837",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent with RMSprop (L1 Regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de05615a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eta_vals = np.logspace(-5, -1, 5)\n",
    "lambda_vals = np.logspace(-5, 1, 5)\n",
    "hidden_layers = [50, 50]\n",
    "\n",
    "n_eta = len(eta_vals)\n",
    "n_lambda = len(lambda_vals)\n",
    "\n",
    "# Storage\n",
    "models = [[None for _ in range(n_lambda)] for _ in range(n_eta)]\n",
    "train_mse = np.zeros((n_eta, n_lambda))\n",
    "test_mse = np.zeros((n_eta, n_lambda))\n",
    "\n",
    "# Grid search\n",
    "for i, eta in enumerate(eta_vals):\n",
    "    for j, lam in enumerate(lambda_vals):\n",
    "        # Create and train model\n",
    "        model = NeuralNetwork(\n",
    "            network_input_size=1,\n",
    "            layer_output_sizes=hidden_layers + [1],\n",
    "            activations=[Sigmoid(), Sigmoid(), Linear()],\n",
    "            loss=MSE(),\n",
    "            seed=SEED,\n",
    "            lambda_reg=lam,\n",
    "            reg_type='l1' if lam > 0 else None,\n",
    "            weight_init='xavier'\n",
    "        )\n",
    "        \n",
    "        optimizer = RMSprop(eta=eta)\n",
    "        \n",
    "        train(\n",
    "            nn=model,\n",
    "            X_train=X_train_s,\n",
    "            y_train=y_train_s,\n",
    "            X_val=X_test_s,\n",
    "            y_val=y_test_s,\n",
    "            optimizer=optimizer,\n",
    "            epochs=500,\n",
    "            batch_size=16,\n",
    "            stochastic=True,\n",
    "            task='regression',\n",
    "            early_stopping=True,\n",
    "            patience=50,\n",
    "            verbose=False,\n",
    "            seed=SEED\n",
    "        )\n",
    "        \n",
    "        models[i][j] = model\n",
    "        \n",
    "        # Evaluate\n",
    "        y_train_pred = inverse_scale_y(model.predict(X_train_s), y_mean)\n",
    "        y_test_pred = inverse_scale_y(model.predict(X_test_s), y_mean)\n",
    "        y_train_real = inverse_scale_y(y_train_s, y_mean)\n",
    "        \n",
    "        train_mse[i, j] = mse(y_train_real, y_train_pred)\n",
    "        test_mse[i, j] = mse(y_test_real, y_test_pred)\n",
    "\n",
    "min_idx_rms = np.unravel_index(np.argmin(test_mse), test_mse.shape)\n",
    "i_best_rms, j_best_rms = min_idx_rms\n",
    "\n",
    "best_eta_rms = eta_vals[i_best_rms]\n",
    "best_lambda_rms = lambda_vals[j_best_rms]\n",
    "best_test_mse_rms = test_mse[i_best_rms, j_best_rms]\n",
    "best_train_mse_rms = train_mse[i_best_rms, j_best_rms]\n",
    "print(f'Best eta:    {best_eta_rms}')\n",
    "print(f'Best lambda: {best_lambda_rms}')\n",
    "print(f'Best train MSE: {best_train_mse_rms}')\n",
    "print(f'Best test MSE:  {best_test_mse_rms}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19cf1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_eta_heatmap(train_mse, eta_vals, lambda_vals, \n",
    "                   metric_name='MSE', dataset='Training')\n",
    "plt.show()\n",
    "\n",
    "lambda_eta_heatmap(test_mse, eta_vals, lambda_vals, \n",
    "                   metric_name='MSE', dataset='Testing')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c8172c",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent with Adam (L1 Regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83f34f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "eta_vals = np.logspace(-5, -1, 5)\n",
    "lambda_vals = np.logspace(-5, 1, 5)\n",
    "hidden_layers = [50, 50]\n",
    "\n",
    "n_eta = len(eta_vals)\n",
    "n_lambda = len(lambda_vals)\n",
    "\n",
    "# Storage\n",
    "models = [[None for _ in range(n_lambda)] for _ in range(n_eta)]\n",
    "train_mse = np.zeros((n_eta, n_lambda))\n",
    "test_mse = np.zeros((n_eta, n_lambda))\n",
    "\n",
    "# Grid search\n",
    "for i, eta in enumerate(eta_vals):\n",
    "    for j, lam in enumerate(lambda_vals):\n",
    "        # Create and train model\n",
    "        model = NeuralNetwork(\n",
    "            network_input_size=1,\n",
    "            layer_output_sizes=hidden_layers + [1],\n",
    "            activations=[Sigmoid(), Sigmoid(), Linear()],\n",
    "            loss=MSE(),\n",
    "            seed=SEED,\n",
    "            lambda_reg=lam,\n",
    "            reg_type='l1' if lam > 0 else None,\n",
    "            weight_init='xavier'\n",
    "        )\n",
    "        \n",
    "        optimizer = Adam(eta=eta)\n",
    "        \n",
    "        train(\n",
    "            nn=model,\n",
    "            X_train=X_train_s,\n",
    "            y_train=y_train_s,\n",
    "            X_val=X_test_s,\n",
    "            y_val=y_test_s,\n",
    "            optimizer=optimizer,\n",
    "            epochs=500,\n",
    "            batch_size=16,\n",
    "            stochastic=True,\n",
    "            task='regression',\n",
    "            early_stopping=True,\n",
    "            patience=50,\n",
    "            verbose=False,\n",
    "            seed=SEED\n",
    "        )\n",
    "        \n",
    "        models[i][j] = model\n",
    "        \n",
    "        # Evaluate\n",
    "        y_train_pred = inverse_scale_y(model.predict(X_train_s), y_mean)\n",
    "        y_test_pred = inverse_scale_y(model.predict(X_test_s), y_mean)\n",
    "        y_train_real = inverse_scale_y(y_train_s, y_mean)\n",
    "        \n",
    "        train_mse[i, j] = mse(y_train_real, y_train_pred)\n",
    "        test_mse[i, j] = mse(y_test_real, y_test_pred)\n",
    "\n",
    "\n",
    "min_idx_adam = np.unravel_index(np.argmin(test_mse), test_mse.shape)\n",
    "i_best_adam, j_best_adam = min_idx_adam\n",
    "\n",
    "best_eta_adam = eta_vals[i_best_adam]\n",
    "best_lambda_adam = lambda_vals[j_best_adam]\n",
    "best_test_mse_adam = test_mse[i_best_adam, j_best_adam]\n",
    "best_train_mse_adam = train_mse[i_best_adam, j_best_adam]\n",
    "print(f'Best eta:    {best_eta_adam}')\n",
    "print(f'Best lambda: {best_lambda_adam}')\n",
    "print(f'Best train MSE: {best_train_mse_adam}')\n",
    "print(f'Best test MSE:  {best_test_mse_adam}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9307d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_eta_heatmap(train_mse, eta_vals, lambda_vals, \n",
    "                   metric_name='MSE', dataset='Training')\n",
    "plt.show()\n",
    "\n",
    "lambda_eta_heatmap(test_mse, eta_vals, lambda_vals, \n",
    "                   metric_name='MSE', dataset='Testing')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7238c3e3",
   "metadata": {},
   "source": [
    "# Comparing optimization algorithms with Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4796155",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"....\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Lasso (Scikit-Learn):     {lasso_mse:.6f}\")\n",
    "print(f\"NN + RMSprop:             {best_test_mse_rms:.6f}   (eta={best_eta_rms:.4f})   (lambda={best_lambda_rms:.6f})\")\n",
    "print(f\"NN + Adam:                {best_test_mse_adam:.6f}  (eta={best_eta_adam:.4f})  (lambda={best_lambda_adam:.6f})\")\n",
    "print(\"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Project 2",
   "language": "python",
   "name": "project2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
